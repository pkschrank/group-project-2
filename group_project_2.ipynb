{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568a84f3",
   "metadata": {},
   "source": [
    "# S&P 500 Signal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fed61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach:\n",
    "1. Create features\n",
    "2. Winsorize data\n",
    "3. Test, Train split data\n",
    "4. Scale the test and train data\n",
    "6. Original, Oversample, and Undersample the data\n",
    "7. Apply RandomForestClassifier, XGBoost, and LightBoost to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ca0b8",
   "metadata": {},
   "source": [
    "## Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d6441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Yahoo Finance\n",
    "!pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ec5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SciKit Learn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44842552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install XGBoost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LightBoost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f909e88",
   "metadata": {},
   "source": [
    "## Import Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92216ef8-6013-4ff6-b1f7-0d91479ef60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries and dependencies\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a26f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b852a",
   "metadata": {},
   "source": [
    "## Retrieve and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive data\n",
    "sp500 = yf.Ticker('^GSPC')\n",
    "sp500 = sp500.history(period='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop timezone from datetime\n",
    "sp500 = sp500.reset_index()\n",
    "sp500['Date'] = sp500['Date'].dt.tz_localize(None)\n",
    "sp500.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last rows of the DataFrame\n",
    "sp500 = sp500.tail(24252) # Get max available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd67a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ced6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stock df\n",
    "stock_df = pd.DataFrame(sp500).dropna()\n",
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b09783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "stock_df.drop(columns={'Volume', 'Dividends', 'Stock Splits'}, inplace=True)\n",
    "\n",
    "# Sort by ascending date\n",
    "stock_df = stock_df.sort_values(by=\"Date\", ascending=True)\n",
    "\n",
    "# Review the first and last five rows of the DataFrame\n",
    "display(stock_df.head())\n",
    "display(stock_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename dataframe to data\n",
    "data = stock_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71303212",
   "metadata": {},
   "source": [
    "## Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e997f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Moving Averages\n",
    "data['SMA10'] = data['Close'].rolling(window=10).mean()\n",
    "data['SMA20'] = data['Close'].rolling(window=20).mean()\n",
    "data['SMA30'] = data['Close'].rolling(window=20).mean()\n",
    "data['SMA50'] = data['Close'].rolling(window=50).mean()\n",
    "data['SMA100'] = data['Close'].rolling(window=100).mean()\n",
    "data['SMA200'] = data['Close'].rolling(window=200).mean()\n",
    "\n",
    "# RSI\n",
    "def rsi(data, window=14):\n",
    "    delta = data['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "data['RSI'] = rsi(data)\n",
    "\n",
    "# MACD\n",
    "data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "data['SL'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "data['BollM'] = data['Close'].rolling(window=20).mean()\n",
    "data['BollU'] = data['BollM'] + (2 * data['Close'].rolling(window=20).std())\n",
    "data['BollL'] = data['BollM'] - (2 * data['Close'].rolling(window=20).std())\n",
    "\n",
    "# Identify crossover signal for Target Column\n",
    "# Close < Bollinger Mid and RSI < 50 and MACD < 0\n",
    "data['Signal'] = np.where((data['Close'] < data['BollM']) & (data['RSI'] < 50) & (data['MACD'] < 0), 1, 0)\n",
    "\n",
    "# Calculate return\n",
    "data['Return'] = data['Close'].pct_change().shift(-1)  # Next day's return\n",
    "\n",
    "# Label Data\n",
    "# Buy ONLY if all Crossover conditions are met\n",
    "# Assume profitable if return > 0%\n",
    "data['Target'] = np.where((data['Signal'] > 0) & (data['Return'] > 0.0), 1, 0)\n",
    "\n",
    "# Prepare dataset\n",
    "features = ['SMA10', 'SMA20', 'SMA30', 'SMA50', 'SMA100', 'SMA200', 'Signal', 'RSI', 'MACD', 'SL', 'BollM', 'BollU', 'BollL']\n",
    "dataset = data.dropna()[features + ['Target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bd659",
   "metadata": {},
   "source": [
    "## Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Moving Averages\n",
    "data['SMA10'] = data['Close'].rolling(window=10).mean()\n",
    "data['SMA20'] = data['Close'].rolling(window=20).mean()\n",
    "data['SMA30'] = data['Close'].rolling(window=20).mean()\n",
    "data['SMA50'] = data['Close'].rolling(window=50).mean()\n",
    "data['SMA100'] = data['Close'].rolling(window=100).mean()\n",
    "data['SMA200'] = data['Close'].rolling(window=200).mean()\n",
    "\n",
    "# RSI\n",
    "def rsi(data, window=14):\n",
    "    delta = data['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "data['RSI'] = rsi(data)\n",
    "\n",
    "# MACD\n",
    "data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "data['SL'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "data['BollM'] = data['Close'].rolling(window=20).mean()\n",
    "data['BollU'] = data['BollM'] + (2 * data['Close'].rolling(window=20).std())\n",
    "data['BollL'] = data['BollM'] - (2 * data['Close'].rolling(window=20).std())\n",
    "\n",
    "# Identify crossover signal for Target Column\n",
    "# Close < Bollinger Mid and RSI < 50 and MACD < 0\n",
    "data['Signal'] = np.where((data['Close'] < data['BollM']) & (data['RSI'] < 50) & (data['MACD'] < 0), 1, 0)\n",
    "\n",
    "# Calculate return\n",
    "data['Return'] = data['Close'].pct_change().shift(-1)  # Next day's return\n",
    "\n",
    "# Label Data\n",
    "# Buy ONLY if all Crossover conditions are met\n",
    "# Assume profitable if return > 0%\n",
    "data['Target'] = np.where((data['Signal'] > 0) & (data['Return'] > 0.0), 1, 0)\n",
    "\n",
    "# Prepare dataset\n",
    "features = ['SMA10', 'SMA20', 'SMA30', 'SMA50', 'SMA100', 'SMA200', 'Signal', 'RSI', 'MACD', 'SL', 'BollM', 'BollU', 'BollL']\n",
    "dataset = data.dropna()[features + ['Target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445bb2f",
   "metadata": {},
   "source": [
    "## Perform Winsorization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "data['Open'] = winsorize(np.array(data['Open']), limits=[.05, .05])\n",
    "data['High'] = winsorize(np.array(data['High']), limits=[.05, .05])\n",
    "data['Low'] = winsorize(np.array(data['Low']), limits=[.05, .05])\n",
    "data['Close'] = winsorize(np.array(data['Close']), limits=[.05, .05])\n",
    "data['SMA10'] = winsorize(np.array(data['SMA10']), limits=[.05, .05])\n",
    "data['SMA20'] = winsorize(np.array(data['SMA20']), limits=[.05, .05])\n",
    "data['SMA30'] = winsorize(np.array(data['SMA30']), limits=[.05, .05])\n",
    "data['SMA50'] = winsorize(np.array(data['SMA50']), limits=[.05, .05])\n",
    "data['SMA100'] = winsorize(np.array(data['SMA100']), limits=[.05, .05])\n",
    "data['SMA200'] = winsorize(np.array(data['SMA200']), limits=[.05, .05])\n",
    "data['EMA12'] = winsorize(np.array(data['EMA12']), limits=[.05, .05])\n",
    "data['EMA26'] = winsorize(np.array(data['EMA26']), limits=[.05, .05])\n",
    "data['MACD'] = winsorize(np.array(data['MACD']), limits=[.05, .05])\n",
    "data['BollM'] = winsorize(np.array(data['BollM']), limits=[.05, .05])\n",
    "data['BollU'] = winsorize(np.array(data['BollU']), limits=[.05, .05])\n",
    "data['BollL'] = winsorize(np.array(data['BollL']), limits=[.05, .05])\n",
    "data['SL'] = winsorize(np.array(data['SL']), limits=[.05, .05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4951b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.boxplot(data=data)\n",
    "plt.title(\"Boxplot for Outlier Detection - Train\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9a444",
   "metadata": {},
   "source": [
    "## Perform Train and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test sets\n",
    "X = dataset[features]\n",
    "y = dataset['Target']\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff348f",
   "metadata": {},
   "source": [
    "## Perform Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled arrays back to DataFrames to maintain column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93d1cf",
   "metadata": {},
   "source": [
    "# Perform Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8d6fe",
   "metadata": {},
   "source": [
    "## Original Scaled Data with Untuned RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the model\n",
    "train_pred = clf.predict(X_train_scaled)\n",
    "test_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Generate classification report\n",
    "# Print scores\n",
    "print(\"Balanced Accuracy Scores\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "x = balanced_accuracy_score(y_train, train_pred)\n",
    "y = balanced_accuracy_score(y_test, test_pred)\n",
    "print(balanced_accuracy_score(y_train, train_pred),'training')\n",
    "print(balanced_accuracy_score(y_test, test_pred),'testing')\n",
    "print(round((x-y), 16),'variance')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Classification Report\")\n",
    "report = classification_report(y_test, test_pred, zero_division=1)\n",
    "print(report)\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9e83e",
   "metadata": {},
   "source": [
    "## Over Sampled Scaled Data with Untuned RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ce977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomOverSampler from imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate a RandomOversampler instance\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the training data to the `RandomOverSampler` model\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count distinct values\n",
    "y_oversampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "ros_clf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "ros_clf.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Predict using the model\n",
    "train_pred = ros_clf.predict(X_train_scaled)\n",
    "test_pred = ros_clf.predict(X_test_scaled)\n",
    "\n",
    "# Generate classification report\n",
    "# Print scores\n",
    "print(\"Balanced Accuracy Scores\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "x = balanced_accuracy_score(y_train, train_pred)\n",
    "y = balanced_accuracy_score(y_test, test_pred)\n",
    "print(balanced_accuracy_score(y_train, train_pred),'training')\n",
    "print(balanced_accuracy_score(y_test, test_pred),'testing')\n",
    "print(round((x-y), 16),'variance')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Classification Report\")\n",
    "report = classification_report(y_test, test_pred, zero_division=1)\n",
    "print(report)\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c86b2d",
   "metadata": {},
   "source": [
    "## Under Sampled Scaled Data with Untuned RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5af776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomUnderSampler from imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate a RandomOversampler instance\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "\n",
    "# Fit the training data to the `RandomOverSampler` model\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count distinct values\n",
    "y_undersampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rus_clf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "rus_clf.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "# Predict using the model\n",
    "train_pred = rus_clf.predict(X_train_scaled)\n",
    "test_pred = rus_clf.predict(X_test_scaled)\n",
    "\n",
    "# Generate classification report\n",
    "# Print scores\n",
    "print(\"Balanced Accuracy Scores\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "x = balanced_accuracy_score(y_train, train_pred)\n",
    "y = balanced_accuracy_score(y_test, test_pred)\n",
    "print(balanced_accuracy_score(y_train, train_pred),'training')\n",
    "print(balanced_accuracy_score(y_test, test_pred),'testing')\n",
    "print(round((x-y), 16),'variance')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Classification Report\")\n",
    "report = classification_report(y_test, test_pred, zero_division=1)\n",
    "print(report)\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be3eb0",
   "metadata": {},
   "source": [
    "## Original Scaled Data and Untuned XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "xgb_clf = XGBClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the model\n",
    "train_pred = xgb_clf.predict(X_train_scaled)\n",
    "test_pred = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Plot feature importance\n",
    "from xgboost import plot_importance\n",
    "plot_importance(xgb_clf)\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "# Print scores\n",
    "print(\"Balanced Accuracy Scores\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "x = balanced_accuracy_score(y_train, train_pred)\n",
    "y = balanced_accuracy_score(y_test, test_pred)\n",
    "print(balanced_accuracy_score(y_train, train_pred),'training')\n",
    "print(balanced_accuracy_score(y_test, test_pred),'testing')\n",
    "print(round((x-y), 16),'variance')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Classification Report\")\n",
    "report = classification_report(y_test, test_pred, zero_division=1)\n",
    "print(report)\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ebeb7",
   "metadata": {},
   "source": [
    "## Under Sampled Scaled Data and Untuned XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd17357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "xgb_rus_clf = XGBClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "xgb_rus_clf.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "# Predict using the model\n",
    "train_pred = xgb_rus_clf.predict(X_train_scaled)\n",
    "test_pred = xgb_rus_clf.predict(X_test_scaled)\n",
    "\n",
    "# Plot feature importance\n",
    "plot_importance(xgb_rus_clf)\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "# Print scores\n",
    "print(\"Balanced Accuracy Scores\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "x = balanced_accuracy_score(y_train, train_pred)\n",
    "y = balanced_accuracy_score(y_test, test_pred)\n",
    "print(balanced_accuracy_score(y_train, train_pred),'training')\n",
    "print(balanced_accuracy_score(y_test, test_pred),'testing')\n",
    "print(round((x-y), 16),'variance')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Classification Report\")\n",
    "report = classification_report(y_test, test_pred, zero_division=1)\n",
    "print(report)\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11c559",
   "metadata": {},
   "source": [
    "## Under Sampled Scaled Data with XGBoost Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the following values for learning_rate\n",
    "rate = np.arange(0.01, 1.1, 0.01)\n",
    "models = {'train_score': [], 'test_score': [], 'learning_rate': []}\n",
    "\n",
    "# Loop through each value in learning_rates\n",
    "for r in rate:\n",
    "    # Initialize the classifier with parameter variables\n",
    "    xgb_rus_clf = XGBClassifier(learning_rate = r, tree_method='approx', random_state=1)\n",
    "\n",
    "    # Fit the undersampled data the new model\n",
    "    xgb_rus_clf.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "    # Make predictions\n",
    "    train_pred = xgb_rus_clf.predict(X_train_scaled)\n",
    "    test_pred = xgb_rus_clf.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate balanced accuracy scores\n",
    "    train_score = balanced_accuracy_score(y_train, train_pred)\n",
    "    test_score = balanced_accuracy_score(y_test, test_pred)\n",
    "\n",
    "    # Append scores\n",
    "    models['train_score'].append(train_score)\n",
    "    models['test_score'].append(test_score)\n",
    "    models['learning_rate'].append(r)\n",
    "\n",
    "# Create a dataframe from the models dictionary with learning_rate as the index\n",
    "models_df = pd.DataFrame(models).set_index('learning_rate')\n",
    "\n",
    "# Display df\n",
    "display(models_df.sort_values(by='test_score', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fe4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by test_score in descending order and get the top 5\n",
    "top_learning_rates = models_df.sort_values(by='test_score', ascending=False).head(5).index.tolist()\n",
    "\n",
    "# Display the top 5 \n",
    "top_learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d93775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "models_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18609377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the following values for n_estimators\n",
    "estimators = range(100, 200, 1)\n",
    "models = {'train_score': [], 'test_score': [], 'n_estimators': []}\n",
    "\n",
    "# Loop through each value in n_estimators\n",
    "for n in estimators:\n",
    "    # Initialize the classifier with parameter variables\n",
    "    xgb_rus_clf = XGBClassifier(n_estimators = n, tree_method='approx', random_state=1)\n",
    "\n",
    "    # Fit the undersampled data the new model\n",
    "    xgb_rus_clf.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "    # Make predictions\n",
    "    train_pred = xgb_rus_clf.predict(X_train_scaled)\n",
    "    test_pred = xgb_rus_clf.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate balanced accuracy scores\n",
    "    train_score = balanced_accuracy_score(y_train, train_pred)\n",
    "    test_score = balanced_accuracy_score(y_test, test_pred)\n",
    "\n",
    "    # Append scores\n",
    "    models['train_score'].append(train_score)\n",
    "    models['test_score'].append(test_score)\n",
    "    models['n_estimators'].append(n)\n",
    "\n",
    "# Create a dataframe from the models dictionary with n_estimators as the index\n",
    "models_df = pd.DataFrame(models).set_index('n_estimators')\n",
    "\n",
    "# Display df\n",
    "display(models_df.sort_values(by='test_score', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by test_score in descending order and get the top 5\n",
    "top_n_estimators = models_df.sort_values(by='test_score', ascending=False).head(5).index.tolist()\n",
    "\n",
    "# Display the top 5\n",
    "top_n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "models_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745dd0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b112d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9417042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1813d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84016285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd3b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd779e7b-ee5b-41e3-beee-768afc0eec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLK (2520, 7)\n",
      "XLV (2520, 7)\n",
      "XLE (2520, 7)\n",
      "VNQ (2520, 7)\n",
      "XLF (2520, 7)\n",
      "XLB (2520, 7)\n",
      "XLU (2520, 7)\n",
      "XLI (2520, 7)\n",
      "XLP (2520, 7)\n",
      "XLY (2520, 7)\n",
      "XTL (2520, 7)\n"
     ]
    }
   ],
   "source": [
    "# Stock list\n",
    "stock_list = [\n",
    "                'XLK',\n",
    "                'XLV',\n",
    "                'XLE',\n",
    "                'VNQ',\n",
    "                'XLF',\n",
    "                'XLB',\n",
    "                'XLU',\n",
    "                'XLI',\n",
    "                'XLP',\n",
    "                'XLY',\n",
    "                'XTL',\n",
    "              ]\n",
    "\n",
    "# Define dictionary\n",
    "stock_df = {}\n",
    "\n",
    "# Loop through stocks \n",
    "for stock in stock_list:\n",
    "    # Read the data into DataFrames\n",
    "    df = pd.read_csv(f'Resources/{stock}.csv')\n",
    "    \n",
    "    # Trim to last 10 years\n",
    "    stock_df[stock] = df.iloc[-2520:]\n",
    "    \n",
    "    # Confirm shape\n",
    "    print(f'{stock}',stock_df[stock].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529a4451-0a6d-47ae-86e8-601b22a2ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>38.220001</td>\n",
       "      <td>38.009998</td>\n",
       "      <td>38.090000</td>\n",
       "      <td>33.428440</td>\n",
       "      <td>5427200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>38.049999</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>38.020000</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>33.524986</td>\n",
       "      <td>3767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>38.180000</td>\n",
       "      <td>38.380001</td>\n",
       "      <td>37.910000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>33.349468</td>\n",
       "      <td>8471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>37.919998</td>\n",
       "      <td>38.209999</td>\n",
       "      <td>37.880001</td>\n",
       "      <td>38.150002</td>\n",
       "      <td>33.481102</td>\n",
       "      <td>5111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>2014-06-26</td>\n",
       "      <td>38.180000</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>37.889999</td>\n",
       "      <td>38.110001</td>\n",
       "      <td>33.446007</td>\n",
       "      <td>11352300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>231.350006</td>\n",
       "      <td>232.169998</td>\n",
       "      <td>230.490005</td>\n",
       "      <td>231.410004</td>\n",
       "      <td>231.004745</td>\n",
       "      <td>4338900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>232.449997</td>\n",
       "      <td>232.589996</td>\n",
       "      <td>228.039993</td>\n",
       "      <td>228.809998</td>\n",
       "      <td>228.409302</td>\n",
       "      <td>6621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>228.860001</td>\n",
       "      <td>229.759995</td>\n",
       "      <td>227.369995</td>\n",
       "      <td>228.410004</td>\n",
       "      <td>228.009995</td>\n",
       "      <td>6780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>225.639999</td>\n",
       "      <td>226.660004</td>\n",
       "      <td>222.360001</td>\n",
       "      <td>222.419998</td>\n",
       "      <td>222.419998</td>\n",
       "      <td>6874300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>224.050003</td>\n",
       "      <td>226.619995</td>\n",
       "      <td>222.789993</td>\n",
       "      <td>226.500000</td>\n",
       "      <td>226.500000</td>\n",
       "      <td>4563100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2520 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "3897  2014-06-20   38.200001   38.220001   38.009998   38.090000   33.428440   \n",
       "3898  2014-06-23   38.049999   38.200001   38.020000   38.200001   33.524986   \n",
       "3899  2014-06-24   38.180000   38.380001   37.910000   38.000000   33.349468   \n",
       "3900  2014-06-25   37.919998   38.209999   37.880001   38.150002   33.481102   \n",
       "3901  2014-06-26   38.180000   38.200001   37.889999   38.110001   33.446007   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "6412  2024-06-18  231.350006  232.169998  230.490005  231.410004  231.004745   \n",
       "6413  2024-06-20  232.449997  232.589996  228.039993  228.809998  228.409302   \n",
       "6414  2024-06-21  228.860001  229.759995  227.369995  228.410004  228.009995   \n",
       "6415  2024-06-24  225.639999  226.660004  222.360001  222.419998  222.419998   \n",
       "6416  2024-06-25  224.050003  226.619995  222.789993  226.500000  226.500000   \n",
       "\n",
       "        Volume  \n",
       "3897   5427200  \n",
       "3898   3767100  \n",
       "3899   8471300  \n",
       "3900   5111900  \n",
       "3901  11352300  \n",
       "...        ...  \n",
       "6412   4338900  \n",
       "6413   6621500  \n",
       "6414   6780400  \n",
       "6415   6874300  \n",
       "6416   4563100  \n",
       "\n",
       "[2520 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access a specific DataFrame\n",
    "stock_df['XLK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ee26c-90ad-4f98-b600-9ccc20743e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
